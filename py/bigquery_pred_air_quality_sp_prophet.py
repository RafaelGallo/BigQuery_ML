# -*- coding: utf-8 -*-
"""BigQuery_pred_Air_quality_SP_Prophet

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1saT1FGwOv4yLhcz1E0j5k4ivDvNSYq1H
"""

!pip install watermark
!pip install prophet
!pip install neuralprophet

# Commented out IPython magic to ensure Python compatibility.
# Importação das bibliotecas

# Bibliotecas sistema
import re
import unicodedata
import itertools

# Biblioteca para manipulação de arquivos
import pandas as pd
import numpy as np

# Visualização de dados
import plotly
import seaborn as sns
import matplotlib.pylab as pl
import matplotlib as m
import matplotlib as mpl
import matplotlib.pyplot as plt
import plotly.express as px
from matplotlib import pyplot as plt

# Carregar as versões das bibliotecas
import watermark

# Versões das bibliotecas
# %reload_ext watermark
# %watermark -a "Versões das bibliotecas" --iversions

# Configuração para os gráficos largura e layout dos graficos
sns.set_theme(style='whitegrid')
plt.style.use('ggplot')

plt.rcParams["figure.figsize"] = (20, 10)
pd.set_option('display.expand_frame_repr', False)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)

m.rcParams['axes.labelsize'] = 15
m.rcParams['xtick.labelsize'] = 15
m.rcParams['ytick.labelsize'] = 15
m.rcParams['text.color'] = 'k'

# Warnings retirar alertas
import warnings
warnings.filterwarnings("ignore")

# Versão do python
from platform import python_version
print('Versão python neste Jupyter Notebook:', python_version())

# @title Setup
from google.colab import auth
from google.cloud import bigquery
from google.colab import data_table

project = 'samara-a2d79' # Project ID inserted based on the query results selected to explore
location = 'US' # Location inserted based on the query results selected to explore
client = bigquery.Client(project=project, location=location)
data_table.enable_dataframe_formatter()
auth.authenticate_user()

"""## Reference SQL syntax from the original job
Use the ```jobs.query```
[method](https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/query) to
return the SQL syntax from the job. This can be copied from the output cell
below to edit the query now or in the future. Alternatively, you can use
[this link](https://console.cloud.google.com/bigquery?j=samara-a2d79:US:bquxjob_2ede8eb6_18b8796b906)
back to BigQuery to edit the query within the BigQuery user interface.
"""

# Running this code will display the query used to generate your previous job

job = client.get_job('bquxjob_2ede8eb6_18b8796b906') # Job ID inserted based on the query results selected to explore
print(job.query)

"""# Result set loaded from BigQuery job as a DataFrame
Query results are referenced from the Job ID ran from BigQuery and the query
does not need to be re-run to explore results. The ```to_dataframe```
[method](https://googleapis.dev/python/bigquery/latest/generated/google.cloud.bigquery.job.QueryJob.html#google.cloud.bigquery.job.QueryJob.to_dataframe)
downloads the results to a Pandas DataFrame by using the BigQuery Storage API.

To edit query syntax, you can do so from the BigQuery SQL editor or in the
```Optional:``` sections below.
"""

# Running this code will read results from your previous job

job = client.get_job('bquxjob_2ede8eb6_18b8796b906') # Job ID inserted based on the query results selected to explore
results = job.to_dataframe()
results

# Mudando variavel
data=results
data

# Filtrar apenas as entradas em que o valor da coluna 'country' é 'Brazil'
brazil_data = data[data['country'] == 'BR']

# salvar esses dados filtrados em um novo arquivo CSV
brazil_data.to_csv('brazil_data.csv', index=False)

# Exibir as primeiras linhas dos dados do Brasil
brazil_data

brazil_data.timestamp.max()

brazil_data.timestamp.min()

# Suponha que você já carregou os dados do arquivo CSV como descrito anteriormente

# Converter a coluna "timestamp" para o tipo de data e hora
brazil_data['timestamp'] = pd.to_datetime(brazil_data['timestamp'])

# Extrair a data da coluna "timestamp" e armazená-la em uma nova coluna "date"
brazil_data['date'] = brazil_data['timestamp'].dt.date

# Agora a coluna "date" contém apenas a parte da data (sem o horário)

# Visualizar o DataFrame
brazil_data

# Definir a coluna "timestamp" como o índice do DataFrame
brazil_data.set_index('timestamp', inplace=True)
brazil_data

# Converter a coluna "timestamp" para o tipo de data e hora
brazil_data['date'] = pd.to_datetime(brazil_data['date'])
brazil_data.info()

brazil_data.pollutant.value_counts()

brazil_data.value.value_counts()

"""# **Análise dados**

## **Análise explorátoria estado São Paulo**
"""

# Gráfico barras particulas poluentes
plt.figure(figsize=(12, 6))
sns.countplot(data=brazil_data, x="pollutant")
plt.title("Poluentes geral")
plt.xlabel("Poluentes")
plt.ylabel("Total")
plt.grid(False)
plt.show()

# Define o nome do arquivo de saída e o formato (PNG no exemplo)
output_file = "Poluentes.png"
plt.savefig(output_file, format="png")

# Opcional para mostrar o gráfico na tela
plt.show()

# Gráfico boxplot
plt.figure(figsize=(12, 6))
sns.boxplot(brazil_data["value"])
plt.title("Gráfico boxplot")
plt.xlabel("Total")
plt.grid(False)
plt.show()

# Define o nome do arquivo de saída e o formato (PNG no exemplo)
output_file = "Poluentes2.png"
plt.savefig(output_file, format="png")

# Opcional para mostrar o gráfico na tela
plt.show()

# Gráfico boxplot
plt.figure(figsize=(12, 6))
sns.boxplot(brazil_data, x="value", y="pollutant")
plt.title("Gráfico boxplot - Poluentes temperatura")
plt.xlabel("Total")
plt.grid(False)

# Define o nome do arquivo de saída e o formato (PNG no exemplo)
output_file = "Poluentes3.png"
plt.savefig(output_file, format="png")

# Opcional para mostrar o gráfico na tela
plt.show()

# 6. Distribuição de algumas variáveis
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
sns.histplot(brazil_data['value'], bins=20, kde=True)
plt.grid(False)
plt.title('')

plt.subplot(1, 2, 2)
sns.histplot(brazil_data['pollutant'], bins=20, kde=True)
plt.title('')
plt.grid(False)

# Define o nome do arquivo de saída e o formato (PNG no exemplo)
output_file = "Poluentes4.png"
plt.savefig(output_file, format="png")

# Opcional para mostrar o gráfico na tela
plt.show()

# Gráfico correlação

# Calcule a matriz de correlação
correlation_matrix = brazil_data.corr()

# Crie um gráfico de heatmap para visualizar a correlação
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Gráfico de Correlação")

# Define o nome do arquivo de saída e o formato (PNG no exemplo)
output_file = "Poluentes5.png"
plt.savefig(output_file, format="png")

# Opcional para mostrar o gráfico na tela
plt.show()

# Filtrar os dados apenas para o poluente "CO"
co_data = brazil_data[brazil_data['pollutant'] == 'pm10']

# Usar groupby para agrupar os dados por algum critério, por exemplo, por ano
co_data_grouped = co_data.groupby(co_data['date'].dt.year)

# Plotar um gráfico de linha usando Seaborn
plt.figure(figsize=(12, 6))
sns.set(style="whitegrid")
sns.lineplot(data=co_data_grouped['value'].mean(), marker="o")
plt.xlabel('Ano')
plt.ylabel('Média de CO')
plt.title('Série Temporal Média de pm10 por Ano')
plt.grid(False)

# Define o nome do arquivo de saída e o formato (PNG no exemplo)
output_file = "Série_Poluentes5.png"
plt.savefig(output_file, format="png")

# Opcional para mostrar o gráfico na tela
plt.show()

# Calcular a média dos valores por cidade
average_by_city = brazil_data.groupby('city')['value'].mean()

# Criar o gráfico de barras
plt.figure(figsize=(35.5, 10))
plt.bar(average_by_city.index, average_by_city.values)
plt.xlabel('Cidade')
plt.ylabel('Média de Valor')
plt.title('Média de Valor por Cidade')
plt.grid(False)

# Rotacionar os rótulos do eixo x em 45 graus
plt.xticks(rotation=50)

# Define o nome do arquivo de saída e o formato (PNG no exemplo)
output_file = "Série_Poluentes25.png"
plt.savefig(output_file, format="png")

# Opcional para mostrar o gráfico na tela
plt.show()

# Calcular a média dos valores por cidade
average_by_city = brazil_data.groupby('location')['value'].mean()

# Criar o gráfico de barras
plt.figure(figsize=(35.5, 10))
plt.bar(average_by_city.index, average_by_city.values)
plt.xlabel('Cidade')
plt.ylabel('Média de Valor')
plt.title('Média de Valor por Cidade')

# Rotacionar os rótulos do eixo x em 45 graus
plt.xticks(rotation=75)
plt.grid(False)

# Define o nome do arquivo de saída e o formato (PNG no exemplo)
output_file = "Série_Poluentes235.png"
plt.savefig(output_file, format="png")

# Opcional para mostrar o gráfico na tela
plt.show()

# Calcular a média dos valores por cidade
average_by_city = brazil_data.groupby('city')['value'].mean()

# Criar o gráfico de linha
plt.figure(figsize=(35.5, 10))
plt.plot(average_by_city.index, average_by_city.values, marker='o', linestyle='-')
plt.xlabel('Cidade')
plt.ylabel('Média de Valor')
plt.title('Média de Valor por Cidade')
plt.grid(False)

# Rotacionar os rótulos do eixo x em 45 graus
plt.xticks(rotation=75)

# Define o nome do arquivo de saída e o formato (PNG no exemplo)
output_file = "Série_Poluentes2335.png"
plt.savefig(output_file, format="png")

# Opcional para mostrar o gráfico na tela
plt.show()

# Calcular a média dos valores por cidade
average_by_city = brazil_data.groupby('location')['value'].mean()

# Criar o gráfico de linha
plt.figure(figsize=(35.5, 10))
plt.plot(average_by_city.index, average_by_city.values, marker='o', linestyle='-')
plt.xlabel('Cidade')
plt.ylabel('Média de Valor')
plt.title('Média de Valor por Cidade')
plt.grid(False)

# Rotacionar os rótulos do eixo x em 45 graus
plt.xticks(rotation=75)

# Define o nome do arquivo de saída e o formato (PNG no exemplo)
output_file = "Série_Poluentes22335.png"
plt.savefig(output_file, format="png")

# Opcional para mostrar o gráfico na tela
plt.show()

# Filtrar os dados apenas para a cidade de São Paulo
sao_paulo_data = brazil_data[brazil_data['city'] == 'São Paulo']

# Calcular a média dos valores para São Paulo
mean_sao_paulo = sao_paulo_data.groupby('location')['value'].mean()

# Criar um gráfico de linha
plt.figure(figsize=(20.5, 10))
plt.plot(mean_sao_paulo.index, mean_sao_paulo.values, marker='o', linestyle='-', color="green")
plt.xlabel('regiãoes')
plt.ylabel('Média de Valor')
plt.title('Média de Valor em São Paulo por região')
plt.grid(False)

# Rotacionar os rótulos do eixo x em 45 graus
plt.xticks(rotation=25)

# Define o nome do arquivo de saída e o formato (PNG no exemplo)
output_file = "Série_Poluentes_22335.png"
plt.savefig(output_file, format="png")

# Opcional para mostrar o gráfico na tela
plt.show()

# Calcular a média dos valores para São Paulo
mean_sao_paulo = sao_paulo_data.groupby('pollutant')['value'].mean()

# Criar um gráfico de linha
plt.figure(figsize=(15, 5))
plt.plot(mean_sao_paulo.index, mean_sao_paulo.values, marker='o', linestyle='-')
plt.xlabel('Poluentes')
plt.ylabel('Média de Valor')
plt.title('Média de Valor em São Paulo por Poluente')
plt.grid(False)

# Rotacionar os rótulos do eixo x em 45 graus
plt.xticks(rotation=25)

output_file = "Série_Poluentes_25.png"
plt.savefig(output_file, format="png")

# Opcional para mostrar o gráfico na tela
plt.show()

# Agrupe os dados por "pollutant"
grouped_data = brazil_data.groupby('pollutant')

# Crie um gráfico de linha usando Seaborn
plt.figure(figsize=(35.5, 10))  # Define o tamanho da figura

for name, group in grouped_data:
    sns.lineplot(x='location', y='value', data=group, label=name)

plt.xlabel('Data')
plt.ylabel('Valor')
plt.title('Gráfico de Linha por Poluente')
plt.legend(title='Poluente')
plt.grid(False)

# Rotacionar os rótulos do eixo x em 45 graus
plt.xticks(rotation=78)

output_file = "Série_Poluentes3_5.png"
plt.savefig(output_file, format="png")

# Opcional para mostrar o gráfico na tela
plt.show()

# Agrupe os dados por "pollutant"
grouped_data = brazil_data.groupby('pollutant')

# Crie um gráfico de linha usando Seaborn
plt.figure(figsize=(35.5, 10))  # Define o tamanho da figura

for name, group in grouped_data:
    sns.lineplot(x='city', y='value', data=group, label=name)

plt.xlabel('Data')
plt.ylabel('Valor')
plt.title('Gráfico de Linha por Poluente')
plt.legend(title='Poluente')
plt.grid(False)

# Rotacionar os rótulos do eixo x em 45 graus
plt.xticks(rotation=78)

output_file = "Série_Poluentes_35.png"
plt.savefig(output_file, format="png")

# Opcional para mostrar o gráfico na tela
plt.show()

"""# **Pré-processamento**"""

brazil_data

"""# **Limpeza dados**"""

# identificar valores ausentes
brazil_data.isnull()

# Identificar valores não ausentes
brazil_data.notnull()

#  identificar duplicatas
brazil_data.duplicated()

# Conte os valores nulos em cada coluna
brazil_data_valores_nulos = brazil_data.isnull().sum()
brazil_data_valores_nulos

# Conte os valores nulos em cada coluna
valores_nulos = brazil_data.isnull().sum()

# Conte o total de valores nulos em todo o DataFrame
total_valores_nulos = valores_nulos.sum()

# Exiba a contagem de valores nulos em cada coluna e o total
print("Valores Nulos por Coluna:")
print(valores_nulos)
print(f"Total de Valores Nulos em Todo o DataFrame: {total_valores_nulos}")

# Remova todas as linhas que contenham valores nulos
df_sem_nulos = brazil_data.dropna()
df_sem_nulos

# Se você quiser remover colunas que contenham valores nulos, você pode usar o argumento "axis=1":
df_sem_nulos = brazil_data.dropna(axis=1)

# Se você desejar remover apenas linhas onde todas as colunas sejam nulas, use o argumento "how='all'":
df_sem_nulos = brazil_data.dropna(how='all')
df_sem_nulos

# Remova todas as linhas duplicadas no DataFrame
df_sem_duplicatas = brazil_data.drop_duplicates().sum()
df_sem_duplicatas

"""# **Remoção Outliers**"""

plt.figure(figsize=(10, 5))
sns.boxplot(brazil_data["value"])
plt.title("Gráfico boxplot com dados Outliers")
plt.xlabel("Temperatura")
plt.ylabel("Total")

# Importando biblioteca
from scipy import stats

# Método Estatístico (Z-Score): O método do Z-Score calcula o desvio padrão das observações e
# remove aquelas que estão muito distantes da média.
z_scores = np.abs(stats.zscore(brazil_data["value"]))
threshold = 3  # Ajuste esse valor conforme necessário
df_no_outliers_1 = brazil_data[(z_scores < threshold)]

# IQR (Intervalo Interquartil): O método do IQR identifica os quartis e remove as observações fora do intervalo IQR.

Q1 = brazil_data["value"].quantile(0.25)
Q3 = brazil_data["value"].quantile(0.75)

IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

df_no_outliers_2 = brazil_data[(brazil_data["value"] >= lower_bound) & (brazil_data["value"] <= upper_bound)]
df_no_outliers_2

# Método de Isolation Forest: O Isolation Forest é um algoritmo de aprendizado de máquina que detecta outliers
# usando uma abordagem baseada em árvores.

# Importando modelo
from sklearn.ensemble import IsolationForest

# Criando instância modelo
# Ajuste o valor de "contamination" conforme necessário
clf = IsolationForest(contamination=0.05)
clf

# Previsão model
outliers = clf.fit_predict(brazil_data[["value"]])

# Visualizando novo dataframe - df_no_outliers
df_no_outliers = brazil_data[outliers != -1]
df_no_outliers

#plt.figure(figsize=(15, 5))
sns.boxplot(data=df_no_outliers, x="pollutant", y="value")

plt.figure(figsize=(10, 5))
sns.boxplot(df_no_outliers["value"])
plt.title("Gráfico boxplot sem dados Outliers - Váriavel alvo")
plt.xlabel("Temperatura")
plt.ylabel("Total")

"""# **Modelo serie temporal**"""

!pip install prophet

# Renomenando colunas para modelo
df_no_outliers = df_no_outliers.rename(columns={"date": "ds", "value": "y"})
df_no_outliers

# Importando bilioteca
from prophet import Prophet

# Criando modelo
model = Prophet()

# Treinamento modelo
model.fit(df_no_outliers)

future = model.make_future_dataframe(periods=350)
future.head()

forecast_1 = model.predict(future)
forecast_1

fig = model.plot(forecast_1)

# Components modelo
modelo_serie_temporal_components = model.plot_components(forecast_1)
modelo_serie_temporal_components

# Melhores previsão
forecast_1[['ds',
          'yhat',
          'yhat_lower',
          'yhat_upper']].tail()

# Plot previsão modelo
fig1 = model.plot(forecast_1)
fig1

# Plot modelo
model.plot(forecast_1)

# Importando biblioteca
import joblib

# Suponha que 'model' seja o seu modelo treinado
joblib.dump(model, 'modelo_serie_temporal_prophet.pkl')

"""# **Modelo 2 - Neural Prophet**"""

#pip install neuralprophet

df_no_outliers = df_no_outliers.drop_duplicates(subset=["ds"])

df_no_outliers = df_no_outliers.groupby("ds")["y"].sum().reset_index()

# Carregando Bibliotecas série temporal
import prophet
from prophet import Prophet
from neuralprophet import NeuralProphet, set_log_level
from neuralprophet import set_random_seed

# Craindo modelo
model = NeuralProphet()

# Treinamento modelo
model.fit(df_no_outliers, freq='D')

# 30 períodos futuros
future = model.make_future_dataframe(df_no_outliers,
                                     periods=650,
                                     n_historic_predictions=len(df_no_outliers))

# Visualizando
future.head()

# Previsão modelo
forecast = model.predict(future)
forecast

# Plot modelo
model.plot(forecast)

# Parametros modelo
model_fig = model.plot_parameters()
model_fig

# Components modelo
model.plot_components(forecast)

# Plot dos parameters e visualizando sazonalidade modelo
model.plot_parameters(components=["seasonality"])

# Métricas modelo
metrics_model2 = model.test(df_no_outliers)
metrics_model2

## Salvando modelo serie temporal

# Suponha que 'model' seja o seu modelo treinado
joblib.dump(model, 'modelo_neural_prophet.pkl')

"""# **Modelo 3 - Neural Prophet Sazonalidade**"""

# Importando biblioteca
from neuralprophet import NeuralProphet, set_log_level

# Criando modelo
model_2 = NeuralProphet(n_changepoints=0,
                        yearly_seasonality=True,
                        weekly_seasonality=False,
                        daily_seasonality=False)

# Treinamento modelo
model_2_fit = model_2.fit(df_no_outliers)

# 450 períodos futuros
model_2_mark = model_2.make_future_dataframe(df_no_outliers,
                                             periods=700,
                                             n_historic_predictions=len(df_no_outliers))
model_2_mark.tail()

# Previsão modelo
model_2_pred = model_2.predict(model_2_mark)
model_2_pred

# Plot previsão
model_2.plot(model_2_pred)

# Plot components
model_2.plot_components(model_2_pred)

# plot parameters
model_2.plot_parameters(components=["seasonality"])

# Métricas modelo
metrics_model = model_2.test(df_no_outliers)
metrics_model

## Salvando modelo serie temporal

# Suponha que 'model' seja o seu modelo treinado
joblib.dump(model_2, 'modelo_neural_prophet_sazonalidade.pkl')

"""# **Modelo 3 - Neural prophet**"""

# Importando biblioteca
from neuralprophet import set_random_seed
from neuralprophet import NeuralProphet, set_log_level

# Modelo Neural prophet
model3 = NeuralProphet(trend_global_local="global",
                       season_global_local="global",
                       changepoints_range=0.8,
                       epochs=300,
                       trend_reg=8)

# Treinamento modelo
model_fit = model3.fit(df_no_outliers, freq="H")

# Previsão modelo
dataset_pred_mark = model3.make_future_dataframe(df_no_outliers, periods=2500)

# Previsão modelo
model_pred3 = model3.predict(dataset_pred_mark)
model_pred3

# Plot previsão modelo
model3.plot(model_pred3)

# Plot parameters
model3.plot_parameters()

# Métricas modelo
test_metrics_global = model3.test(df_no_outliers)
test_metrics_global

## Salvando modelo serie temporal

# Suponha que 'model' seja o seu modelo treinado
joblib.dump(model3, 'modelo_neural_prophet_3.pkl')

df_no_outliers

